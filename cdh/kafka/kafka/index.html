<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Kafka笔记, 张文辉的笔记">
    <meta name="description" content="这是我的博客网站">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Kafka笔记 | 张文辉的笔记</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 6.2.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">张文辉的笔记</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">张文辉的笔记</div>
        <div class="logo-desc">
            
            这是我的博客网站
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Kafka笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/CDH/">
                                <span class="chip bg-color">CDH</span>
                            </a>
                        
                            <a href="/tags/Kafka/">
                                <span class="chip bg-color">Kafka</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/CDH/" class="post-category">
                                CDH
                            </a>
                        
                            <a href="/categories/CDH/Kafka/" class="post-category">
                                Kafka
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-11-06
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="Kafka是什么？"><a href="#Kafka是什么？" class="headerlink" title="Kafka是什么？"></a>Kafka是什么？</h3><p>Kafka是一个<strong>分布式</strong>的基于<strong>发布&#x2F;订阅模式</strong>的<strong>消息队列，</strong>主要应用于大数据实时处理领域。kafka0.9是一个过渡点。</p>
<h3 id="Kafka端口号"><a href="#Kafka端口号" class="headerlink" title="Kafka端口号"></a>Kafka端口号</h3><p>9092 		Kafka通信端口号</p>
<h3 id="消息队列有什么作用？"><a href="#消息队列有什么作用？" class="headerlink" title="消息队列有什么作用？"></a>消息队列有什么作用？</h3><p>1、异步处理，使用消息队列当中间件，进行异步处理，更好的用户体验</p>
<p><img src="/cdh/kafka/kafka/image-20200408195438360.png" alt="image-20200408195438360"></p>
<p>2、秒杀系统</p>
<p>使用消息队列进行来削峰，消除峰值，先进先出，减少秒杀系统的处理压力，只需要取出先进来的前多少名就解决了秒杀系统的高并发</p>
<p><img src="/cdh/kafka/kafka/image-20200408200056295.png" alt="image-20200408200056295"></p>
<p>3、解耦</p>
<p>使用消息队列解耦，案例flume，flume中间件channel就是一个中间件，上下兼容，进行了解耦，如果没有这个中间件，source和sink各自适配，将会非常麻烦</p>
<p><img src="/cdh/kafka/kafka/image-20200408200035955.png" alt="image-20200408200035955"></p>
<h3 id="消息队列的两种模式"><a href="#消息队列的两种模式" class="headerlink" title="消息队列的两种模式"></a>消息队列的两种模式</h3><p>（1）<strong>点对点模式</strong>（一对一，消费者主动拉取数据，消息收到后消息清除）<strong>消息是一次性的</strong>，已经不怎么用了</p>
<p>消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。</p>
<p>消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。<strong>Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费</strong></p>
<p><img src="/cdh/kafka/kafka/image-20200408200325374.png" alt="image-20200408200325374"></p>
<p>（2）<strong>发布&#x2F;订阅模式</strong>（一对多，消费者消费数据之后不会清除消息）是常用的模式,不是一次性的,数据保存在磁盘上</p>
<p>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。<strong>和点对点方式不同，发布到topic的消息会被所有订阅者消费。</strong></p>
<h3 id="Kafka的基本架构"><a href="#Kafka的基本架构" class="headerlink" title="Kafka的基本架构"></a>Kafka的基本架构</h3><p><img src="/cdh/kafka/kafka/image-20200910155746550.png" alt="image-20200910155746550"></p>
<h3 id="Kafka各个组件作用"><a href="#Kafka各个组件作用" class="headerlink" title="Kafka各个组件作用"></a>Kafka各个组件作用</h3><p>1）<strong>Producer</strong> ：消息生产者，就是向kafka broker发消息的客户端；</p>
<p>2）<strong>Consumer</strong> ：消息消费者，向kafka broker取消息的客户端；</p>
<p>3）<strong>Consumer Group （CG）</strong>：消费者组，由<strong>多个consumer组成</strong>。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>4）<strong>Broker</strong> ：一台kafka服务器就是一个broker。<strong>一个集群由多个broker组成</strong>。一个broker可以容纳多个topic。</p>
<p>5）<strong>Topic</strong> ：可以理解为一个队列，生产者和消费者面向的都是一个topic；</p>
<p>6）<strong>Partition</strong>：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列；</p>
<p>7）<strong>Replica</strong>：副本，为防止集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，<strong>一个topic的每个分区都有若干个副本，一个leader和若干个follower。</strong></p>
<p>8）<strong>leader</strong>：每个分区多个副本的“主”，<strong>生产者发送数据的对象，以及消费者消费数据的对象都是leader。</strong></p>
<p>9）<strong>follower</strong>：每个分区多个副本中的“从”，实时从leader中同步数据，<strong>保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。</strong></p>
<h3 id="Kafka基本概念"><a href="#Kafka基本概念" class="headerlink" title="Kafka基本概念"></a>Kafka基本概念</h3><p>Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</p>
<p><strong>topic是逻辑上的概念，而partition是物理上的概念</strong>，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。</p>
<p>offset是一个long型的数字，我们通过这个offset可以确定一条在该partition下的唯一消息。在partition下面是保证了有序性，但是在topic下面没有保证有序性。</p>
<p>消费者组中的每个消费者，都会实时记录自己消费到了哪个offset ，以便出错恢复时，从上次的位置继续消费。</p>
<h3 id="Kafka生产者"><a href="#Kafka生产者" class="headerlink" title="Kafka生产者"></a>Kafka生产者</h3><h4 id="一、分区策略"><a href="#一、分区策略" class="headerlink" title="一、分区策略"></a>一、分区策略</h4><h5 id="1）分区的原因"><a href="#1）分区的原因" class="headerlink" title="1）分区的原因"></a><strong>1</strong>）分区的原因</h5><p>（1）<strong>方便在集群中扩展</strong>，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</p>
<p>（2）<strong>可以提 高并发</strong>，因为可以以Partition为单位读写了。</p>
<p>（3）负载均衡，防止热点数据。</p>
<h5 id="2）分区的规则"><a href="#2）分区的规则" class="headerlink" title="2）分区的规则"></a><strong>2</strong>）分区的规则</h5><p>我们需要将producer发送的数据封装成一个<strong>ProducerRecord</strong>对象。</p>
<p><img src="/cdh/kafka/kafka/image-20200910164708408.png" alt="image-20200910164708408"></p>
<p>（1）指明 partition 的情况下，直接将指明的值直接作为 partiton 值；<br>（2）没有指明 partition 值但有 key 的情况下，将 key 的 <strong>hash 值</strong>与 topic 的 partition 数进行取余得到 partition 值；<br>（3）既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。(黏性分区规则)</p>
<h4 id="二、Producer发送数据可靠性保证"><a href="#二、Producer发送数据可靠性保证" class="headerlink" title="二、Producer发送数据可靠性保证"></a>二、Producer发送数据可靠性保证</h4><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到<strong>ack</strong>，就会进行下一轮的发送，否则重新发送数据</p>
<p><img src="/cdh/kafka/kafka/image-20200910164935464.png" alt="image-20200910164935464"></p>
<h5 id="1）副本数据同步策略"><a href="#1）副本数据同步策略" class="headerlink" title="1）副本数据同步策略"></a><strong>1）副本数据同步策略</strong></h5><table>
<thead>
<tr>
<th><strong>方案</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>半数以上完成同步，就发送ack</strong></td>
<td>延迟低</td>
<td>选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td>
</tr>
<tr>
<td><strong>全部完成同步，才发送ack</strong></td>
<td>选举新的leader时，容忍n台节点的故障，需要n+1个副本</td>
<td>延迟高</td>
</tr>
</tbody></table>
<p><strong>Kafka选择了第二种方案，原因如下：</strong></p>
<p>1.同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</p>
<p>2.虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</p>
<h5 id="2）ISR"><a href="#2）ISR" class="headerlink" title="2）ISR"></a>2）ISR</h5><p>副本同步队列</p>
<p>Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</p>
<h5 id="3）ack应答机制"><a href="#3）ack应答机制" class="headerlink" title="3）ack应答机制"></a><strong>3</strong>）ack应答机制</h5><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。<br>所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。<br>acks参数配置：<br>acks：<br><strong>0</strong>：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；<br><strong>1</strong>：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据</p>
<p><strong>-1</strong>（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</p>
<img src="/cdh/kafka/kafka/Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200910165946929.png" alt="image-20200910165946929" style="zoom: 67%;">

<img src="/cdh/kafka/kafka/Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200910170004399.png" alt="image-20200910170004399" style="zoom:67%;">

<h5 id="4）故障处理细节"><a href="#4）故障处理细节" class="headerlink" title="4）故障处理细节"></a><strong>4</strong>）故障处理细节</h5><p><img src="/cdh/kafka/kafka/image-20200910170106287.png" alt="image-20200910170106287"></p>
<h5 id="（1）follower故障"><a href="#（1）follower故障" class="headerlink" title="（1）follower故障"></a>（1）follower故障</h5><p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</p>
<h5 id="（2）leader故障"><a href="#（2）leader故障" class="headerlink" title="（2）leader故障"></a>（2）leader故障</h5><p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。<strong>（1<strong><strong>）follower</strong></strong>故障</strong></p>
<p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该<strong>follower<strong><strong>的LEO</strong></strong>大于等于该Partition****的HW</strong>，即follower追上leader之后，就可以重新加入ISR了。</p>
<p><strong>（2<strong><strong>）leader</strong></strong>故障</strong></p>
<p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</p>
<p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p>
<h4 id="三、Exactly-Once语义"><a href="#三、Exactly-Once语义" class="headerlink" title="三、Exactly Once语义"></a>三、Exactly Once语义</h4><p>对于某些比较重要的消息，我们需要保证exactly once语义，即<strong>保证每条消息被发送且仅被发送一次。</strong><br>在0.11版本之后，Kafka引入了幂等性机制（idempotent），配合acks &#x3D; -1时的at least once语义，实现了producer到broker的exactly once语义。<br>idempotent + at least once &#x3D; exactly once<br>使用时，只需将enable.idempotence属性设置为true，kafka自动将acks属性设为-1。</p>
<p>kafka幂等性原理：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/EQvY_VyZc-k8SB2c3O6kLA">https://mp.weixin.qq.com/s/EQvY_VyZc-k8SB2c3O6kLA</a></p>
<h3 id="Kafka消费者"><a href="#Kafka消费者" class="headerlink" title="Kafka消费者"></a>Kafka消费者</h3><h4 id="一、消费方式"><a href="#一、消费方式" class="headerlink" title="一、消费方式"></a>一、消费方式</h4><p><strong>consumer采用pull（拉）模式从broker中读取数据。</strong></p>
<p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p>
<p><strong>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</strong></p>
<h4 id="二、分区分配策略"><a href="#二、分区分配策略" class="headerlink" title="二、分区分配策略"></a>二、分区分配策略</h4><p>一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费。<br>Kafka有两种分配策略，一是roundrobin，一是range。</p>
<h5 id="1）roundrobin"><a href="#1）roundrobin" class="headerlink" title="1）roundrobin"></a>1）roundrobin</h5><h5 id="2）range"><a href="#2）range" class="headerlink" title="2）range"></a>2）range</h5><h4 id="三、offset的维护"><a href="#三、offset的维护" class="headerlink" title="三、offset的维护"></a>三、offset的维护</h4><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。<br>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p>
<p>也可以手动维护offset，一般保存在mysql中，因为他有事务，一般将保存offset和保存数据的代码写在一个事务当中，实现精准一次消费。</p>
<h3 id="Kafka为什么快"><a href="#Kafka为什么快" class="headerlink" title="Kafka为什么快?"></a>Kafka为什么快?</h3><p>1)顺序写磁盘</p>
<p>顺序写磁盘，写的过程是一直追加到文件末端，，顺序写之所以快，是因为其省去了大量磁头寻址的时间。顺序写磁盘比内存都快！</p>
<p>2）零拷贝技术</p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1421266">https://cloud.tencent.com/developer/article/1421266</a></p>
<p><img src="/cdh/kafka/kafka/image-20200728105930977.png" alt="image-20200728105930977"></p>
<h3 id="Kafka如何保证consumer只消费一次？"><a href="#Kafka如何保证consumer只消费一次？" class="headerlink" title="Kafka如何保证consumer只消费一次？"></a>Kafka如何保证consumer只消费一次？</h3><p>在consumer消费的时候，在处理完成数据后在提交offset，而不是接收到数据就发送offset </p>
<h3 id="Zookeeper在Kafka中的作用"><a href="#Zookeeper在Kafka中的作用" class="headerlink" title="Zookeeper在Kafka中的作用"></a>Zookeeper在Kafka中的作用</h3><p>Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。<br>Controller的管理工作都是依赖于Zookeeper的。<br>以下为partition的leader选举过程：</p>
<p><img src="/cdh/kafka/kafka/image-20200910174852060.png" alt="image-20200910174852060"></p>
<h3 id="文件存储机制"><a href="#文件存储机制" class="headerlink" title="文件存储机制"></a>文件存储机制</h3><p><img src="/cdh/kafka/kafka/640" alt="img"></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NfkyB9ueApWd5FLFTctA28U1bOvvpgMrqpicIC844Q6ibHkSezAHGYTw1TwMRO5eqx95e98kpia0zbA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p>
<p>由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment(逻辑概念，等于index+log文件)。</p>
<p>每个partition(目录)相当于一个巨型文件被平均分配到多个大小相等的segment(片段)数据文件中（每个segment文件中消息数量不一定相等），这种特性也方便old segment的删除，即方便已被消费的消息的清理，提高磁盘的利用率。每个partition只需要支持顺序读写就行，segment的文件生命周期由服务端配置参数（log.segment.bytes，log.roll.{ms,hours}等若干参数）决定。</p>
<p>每个segment对应两个文件——“.index”文件和“.log”文件。分别表示为segment索引文件和数据文件（引入索引文件的目的就是便于利用二分查找快速定位message位置）。这两个文件的命令规则为：partition全局的第一个segment从0开始，后续每个segment文件名以当前segment的第一条消息的offset命名，数值大小为64位，20位数字字符长度，没有数字用0填充。</p>
<p>这些文件位于一个文件夹下（partition目录），该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。</p>
<p>index和log文件以当前segment的第一条消息的offset命名。下图为index文件和log文件的结构示意图。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NfkyB9ueApWd5FLFTctA28gJ1sqCIcMnEnVhDWT4d9HozwdJdXYTXV6NmnRWJfUU0icXiaoib8Ewu3g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p>
<h4 id="index和log文件详解"><a href="#index和log文件详解" class="headerlink" title="index和log文件详解"></a>index和log文件详解</h4><p>.index索引文件存储大量的索引信息，.log数据文件存储大量消息数据（Message）,索引文件中的元数据指向对应数据文件中Message的物理偏移地址。以index索引文件中的元数据3,497为例，依次在数据文件中表示第三个Message（在全局Partition中表示第368772个message），以及该消息的物理偏移地址为497.</p>
<p>索引和日志文件内部的关系，如图：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NfkyB9ueApWd5FLFTctA287Rm6Cyg5OJqynqkIIywcFt1MpguSIIdk8iagxP1mJCdzo0fT8wwr8Kg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p>
<h4 id="message的结构"><a href="#message的结构" class="headerlink" title="message的结构"></a>message的结构</h4><p>Segment的Log文件由多个Message组成，下面详细说明Message的物理结构，如图：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NfkyB9ueApWd5FLFTctA28SBCpWxUia9YQJ3VgTkVSFfrt0oy2v8T5DWspRXMDJExrZ90hYNWetyw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p>
<p><strong>参数说明:</strong></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2NfkyB9ueApWd5FLFTctA28D5olWpbLOibtiarrw9aQeoovW177zMhOORzokYd2eBasRwZmlL3IY4vA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p>
<p>这里Kafka主要给sparkstream提供服务, 数据提交到kafka，sparkstream处理数据从kafka中拉取数据，能处理多少就拉取多少，有缓存的作用</p>
<p>kafka在<strong>存储数据的时候都是存到磁盘中，一对多的</strong>，消息是持久化的，不是一次性的<strong>，默认存储时间1个星期</strong></p>
<p>kafka集群的机器节点(Broker)相当于一个大分区，这里三个分区组成一个topic(队列)，topic的存储分布到多个broker上，启到负载均衡的作用，为了可靠性，分区后的topic拥有副本，副本保存在不同的节点上，防止全部丢失，每个分区多有很多副本，但只有一个副本是leader，副本的从节点不参与服务,.kafka只有主节点能够进行数据的存储和读取消息，从节点就是起到备份的作用，在主节点故障时,成为新的leader.</p>
<p>consumer随机从kafka里面读取，一个组中的consumer都会有一个标识所以一个组的consumer不会重复读取(消费)数据。尽量保证一个线程对应一个分区</p>
<p>在kafka中,一个partition中的消息只会被group中的一个consumer消费****(同一时刻)****；</p>
<p><strong>一个Topic中的每个partions，只会被一个”订阅者”中的一个consumer消费，不过一个consumer可以同时消费多个partitions中的消息。</strong></p>
<p><strong>*kafka只能保证一个partition中的消息被某个consumer消费时是顺序的；事实上，从Topic角度来说,当有多个partitions时,消息仍不是全局有序的。*</strong></p>
<h3 id="Kafka0-11的安装"><a href="#Kafka0-11的安装" class="headerlink" title="Kafka0.11的安装"></a>Kafka0.11的安装</h3><p>1、下载kafka的jar包</p>
<p><a target="_blank" rel="noopener" href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></p>
<p>2、上传到集群然后解压  三台</p>
<pre><code>tar -zxvf kafka_2.11-0.11.0.0.tgz 
</code></pre>
<p>3、kafka目录下创建datadir文件夹  三台</p>
<pre><code>mkdir logs
</code></pre>
<p>4、修改配置文件</p>
<p>kafka_2.11-0.11.0.2&#x2F;config  修改这个配置文件，三台</p>
<p><strong>每个节点上的broker.id 必须不同</strong>，不能重复</p>
<pre><code class="properties"># The id of the broker. This must be set to a unique integer for each broker.
#这个id三台机器必须不相同
broker.id=0

# Switch to enable topic deletion or not, default value is false
delete.topic.enable=true
num.network.threads=3

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600


############################# Log Basics #############################

# A comma seperated list of directories under which to store log files
log.dirs=/install/kafka_2.11-0.11.0.2/datadir

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;
# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining
# segments don&#39;t drop below log.retention.bytes. Functions independently of log.retention.hours.
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=Linux01:2181,Linux02:2181,Linux03:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0
</code></pre>
<p>5、修改&#x2F;etc&#x2F;profile文件</p>
<p>修改完成后source 刷新配置文件</p>
<pre><code class="properties">export SPARK_HOME=/install/spark-2.2.0-bin-hadoop2.7
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export KAFKA_HOME=/install/kafka_2.11-0.11.0.2
export PATH=$PATH:$KAFKA_HOME/bin
</code></pre>
<h3 id="Kafka的命令行操作"><a href="#Kafka的命令行操作" class="headerlink" title="Kafka的命令行操作"></a>Kafka的命令行操作</h3><h4 id="1、Kafka集群的启动"><a href="#1、Kafka集群的启动" class="headerlink" title="1、Kafka集群的启动"></a>1、Kafka集群的启动</h4><p>在kafka的根目录下，三台</p>
<pre><code class="scala">bin/kafka-server-start.sh -daemon config/server.properties
</code></pre>
<h4 id="2、Kafka集群的关闭"><a href="#2、Kafka集群的关闭" class="headerlink" title="2、Kafka集群的关闭"></a>2、Kafka集群的关闭</h4><p>在kafka的根目录下，三台</p>
<pre><code class="scala">bin/kafka-server-stop.sh stop
</code></pre>
<p><strong>在kafka的根目录下</strong></p>
<h4 id="3、当前服务器中的所有topic"><a href="#3、当前服务器中的所有topic" class="headerlink" title="3、当前服务器中的所有topic"></a><strong>3、当前服务器中的所有topic</strong></h4><pre><code class="scala">bin/kafka-topics.sh --zookeeper Linux02:2181 --list
//查看所有的topic
</code></pre>
<h4 id="4、创建topic"><a href="#4、创建topic" class="headerlink" title="4、创建topic"></a><strong>4、创建topic</strong></h4><pre><code class="scala">bin/kafka-topics.sh --zookeeper Linux02:2181 --create --topic first --partitions 3 --replication-factor 3 
//创建first节点  3个分区  1个分区三个副本

//--topic 定义topic名
//--replication-factor  定义副本数
//--partitions  定义分区数
</code></pre>
<h4 id="5、删除topic"><a href="#5、删除topic" class="headerlink" title="5、删除topic"></a><strong>5、删除topic</strong></h4><pre><code class="scala">bin/kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first
//需要server.properties中设置delete.topic.enable=true否则只是标记删除。

//--topic 定义topic名
//--replication-factor  定义副本数
//--partitions  定义分区数
</code></pre>
<h4 id="6、发送消息"><a href="#6、发送消息" class="headerlink" title="6、发送消息"></a><strong>6、发送消息</strong></h4><p>如果只发送，需要指定消费信息</p>
<pre><code>bin/kafka-console-producer.sh --broker-list Linux02:9092 --topic first
&gt;hello world
&gt;agjasidjdj jsidjfj
</code></pre>
<h4 id="7、消费消息"><a href="#7、消费消息" class="headerlink" title="7、消费消息"></a><strong>7、消费消息</strong></h4><p>–from-beginning   加上这个从头开始读取，没有这个会按照offset的位置来读取</p>
<pre><code class="scala">bin/kafka-console-consumer.sh --bootstrap-server Linux02:9092 --from-beginning --topic first

//--from-beginning：会把主题中以往所有的数据都读取出来。
</code></pre>
<h4 id="8、查看某个Topic的详情"><a href="#8、查看某个Topic的详情" class="headerlink" title="8、查看某个Topic的详情"></a><strong>8、查看某个Topic的详情</strong></h4><pre><code class="scala">bin/kafka-topics.sh --zookeeper Linux02:2181 \
--describe --topic first
</code></pre>
<p><img src="/cdh/kafka/kafka/image-20200409204342145.png" alt="image-20200409204342145"></p>
<h4 id="9、修改分区数"><a href="#9、修改分区数" class="headerlink" title="9、修改分区数"></a><strong>9、修改分区数</strong></h4><pre><code class="scala">bin/kafka-topics.sh --zookeeper hadoop102:2181 --alter --topic first --partitions 6
//只能增加分区不能减少分区
</code></pre>
<h3 id="集群的基准测试-压测"><a href="#集群的基准测试-压测" class="headerlink" title="集群的基准测试(压测)"></a>集群的基准测试(压测)</h3><p>Kafka压测</p>
<p>用Kafka官方自带的脚本，对Kafka进行压测。Kafka压测时，可以查看到哪个地方出现了瓶颈（CPU，内存，网络IO）。一般都是网络IO达到瓶颈。 cpu可以加 内存可以调 网络带宽太贵了</p>
<p>kafka-consumer-perf-test.sh</p>
<p>kafka-producer-perf-test.sh</p>
<p>2）Kafka Producer压力测试</p>
<p>（1）在&#x2F;opt&#x2F;modules&#x2F;kafka&#x2F;bin目录下面有这两个文件。我们来测试一下</p>
<pre><code>[admin@hadoop-yarn kafka]$ bin/kafka-producer-perf-test.sh --topic test --record-size 100 --num-records 100000 --throughput 1000 --producer-props bootstrap.servers=bw66:9092,bw67:9092,bw68:9092
</code></pre>
<p>说明：record-size是一条信息有多大，单位是字节。num-records是总共发送多少条信息。throughput 是每秒多少条信息。（吞吐量）</p>
<p>（2）Kafka会打印下面的信息</p>
<pre><code>5000 records sent, 999.4 records/sec (0.10 MB/sec), 1.9 ms avg latency, 254.0 max latency.

5002 records sent, 1000.4 records/sec (0.10 MB/sec), 0.7 ms avg latency, 12.0 max latency.

5001 records sent, 1000.0 records/sec (0.10 MB/sec), 0.8 ms avg latency, 4.0 max latency.

5000 records sent, 1000.0 records/sec (0.10 MB/sec), 0.7 ms avg latency, 3.0 max latency.

5000 records sent, 1000.0 records/sec (0.10 MB/sec), 0.8 ms avg latency, 5.0 max latency.

100000 records sent, 999.930005 records/sec (0.10 MB/sec), 1.38 ms avg latency, 809.00 ms max latency, 1 ms 50th, 2 ms 95th, 20 ms 99th, 81 ms 99.9th.
</code></pre>
<p>参数解析：本例中一共写入10w条消息，每秒向Kafka写入了<strong>0.10MB</strong>的数据，平均是999.99条消息&#x2F;秒，每次写入的平均延迟为1.38毫秒，最大的延迟为809毫秒。</p>
<p>这就能看出来 ： 每秒中0.1M能否满足我们的需求 延迟时间能否接受？</p>
<p><strong>这个测试环境</strong> <strong>要和实际情况</strong> <strong>联系起来</strong> <strong>你以后每天要产生一亿条</strong> <strong>那你就陪<strong><strong>1</strong></strong>亿</strong> </p>
<p><strong>数据得根据实际情况来！！！！！</strong></p>
<p>3）Kafka Consumer压力测试</p>
<p> 注意：消费的速度一定要大于生产的速度 否则数据就会有堆积</p>
<p>Consumer的测试，如果这四个指标（IO，CPU，内存，网络）都不能改变，考虑增加分区数来提升性能。</p>
<pre><code>[admin@hadoop-yarn kafka]$ 

bin/kafka-consumer-perf-test.sh --zookeeper bw66:2181,bw67:2181,bw68:2181 --topic test --fetch-size 10000 --messages 10000000 --threads 1
</code></pre>
<p>参数说明：</p>
<p>–zookeeper 指定zookeeper的链接信息</p>
<p>–topic 指定topic的名称</p>
<p>–fetch-size 指定每次fetch的数据的大小</p>
<p>–messages 总共要消费的消息个数</p>
<p>测试结果说明：</p>
<p>start.time, <strong>end.time,</strong> data.consumed.in.MB, <strong>MB.sec,</strong> data.consumed.in.nMsg**, nMsg.sec**</p>
<p>2019-02-19 20:29:07:566, <strong>2019-02-19 20:29:12:170,</strong> 9.5368, <strong>2.0714,</strong> 100010, <strong>21722.4153</strong></p>
<p><strong>开始测试时间，测试结束数据，最大吞吐率</strong>9.5368MB&#x2F;s，平均每秒消费<strong>2.0714MB&#x2F;s****，最大每秒消费</strong>100010条，平均每秒消费<strong>21722.4153****条。</strong></p>
<h3 id="项目经验之Kafka机器数量计算"><a href="#项目经验之Kafka机器数量计算" class="headerlink" title="项目经验之Kafka机器数量计算"></a>项目经验之Kafka机器数量计算</h3><p>注意 副本数基本设置为2<br>$$<br>Kafka机器数量（经验公式）&#x3D;2<em>（峰值生产速度</em>副本数&#x2F;100）+1<br>$$</p>
<h4 id="kafka节点有几台？"><a href="#kafka节点有几台？" class="headerlink" title="kafka节点有几台？"></a>kafka节点有几台？</h4><p>先要预估一天大概产生多少数据，然后用Kafka自带的生产压测（只测试Kafka的写入速度，保证数据不积压），计算出峰值生产速度。再根据设定的副本数，就能预估出需要部署Kafka的数量。</p>
<p>100&#x3D;100*1024&#x2F;3600&#x2F;24</p>
<p>比如我们采用压力测试测出写入的速度是10M&#x2F;s一台，峰值的业务数据的速度是50M&#x2F;s。副本数为2。</p>
<p>Kafka机器数量&#x3D;2<em>（50</em>2&#x2F;100）+ 1&#x3D;3台  这个kafka集群能够抗住50M&#x2F;s的数据 已经非常快了！！ <strong>在正常的企业 3台kafka肯定是够了 ！！</strong></p>
<h2 id="Kafka与传统消息队列优缺点"><a href="#Kafka与传统消息队列优缺点" class="headerlink" title="Kafka与传统消息队列优缺点"></a>Kafka与传统消息队列优缺点</h2><h2 id="KafkaAPI"><a href="#KafkaAPI" class="headerlink" title="KafkaAPI"></a>KafkaAPI</h2><h3 id="Producer-API"><a href="#Producer-API" class="headerlink" title="Producer API"></a>Producer API</h3><h4 id="一、消息发送流程"><a href="#一、消息发送流程" class="headerlink" title="一、消息发送流程"></a>一、消息发送流程</h4><p><strong>Kafka的Producer发送消息采用的是异步发送的方式。</strong></p>
<p><strong>在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker</strong>。</p>
<p><img src="/cdh/kafka/kafka/image-20200910175224088.png" alt="image-20200910175224088"></p>
<p><strong>相关参数：</strong><br>batch.size：只有数据积累到batch.size之后，sender才会发送数据。<br>linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。</p>
<h4 id="二、异步发送API"><a href="#二、异步发送API" class="headerlink" title="二、异步发送API"></a>二、异步发送API</h4><p>1）导入依赖</p>
<pre><code class="xml">&lt;dependency&gt;
&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
&lt;version&gt;0.11.0.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>2）编写代码<br>需要用到的类：</p>
<pre><code>KafkaProducer：需要创建一个生产者对象，用来发送数据
ProducerConfig：获取所需的一系列配置参数
ProducerRecord：每条数据都要封装成一个ProducerRecord对象
</code></pre>
<h5 id="1-不带回调函数的API"><a href="#1-不带回调函数的API" class="headerlink" title="1.不带回调函数的API"></a>1.不带回调函数的API</h5><pre><code class="java">package com.atguigu.kafka;

import org.apache.kafka.clients.producer.*;

import java.util.Properties;
import java.util.concurrent.ExecutionException;

public class CustomProducer &#123;

    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);//kafka集群，broker-list
        props.put(&quot;acks&quot;, &quot;all&quot;);
        props.put(&quot;retries&quot;, 1);//重试次数
        props.put(&quot;batch.size&quot;, 16384);//批次大小
        props.put(&quot;linger.ms&quot;, 1);//等待时间
        props.put(&quot;buffer.memory&quot;, 33554432);//RecordAccumulator缓冲区大小
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
        for (int i = 0; i &lt; 100; i++) &#123;
            producer.send(new ProducerRecord&lt;String, String&gt;(&quot;first&quot;, Integer.toString(i), Integer.toString(i)));
        &#125;
        producer.close();
    &#125;
&#125;
</code></pre>
<h5 id="2-带回调函数的API"><a href="#2-带回调函数的API" class="headerlink" title="2.带回调函数的API"></a>2.带回调函数的API</h5><p><img src="/cdh/kafka/kafka/image-20200910191728376.png" alt="image-20200910191728376"></p>
<p><strong>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</strong></p>
<p>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是RecordMetadata和Exception，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p>
<pre><code class="java">package com.atguigu.kafka;

import org.apache.kafka.clients.producer.*;

import java.util.Properties;
import java.util.concurrent.ExecutionException;

public class CustomProducer &#123;

    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);//kafka集群，broker-list
        props.put(&quot;acks&quot;, &quot;all&quot;);
        props.put(&quot;retries&quot;, 1);//重试次数
        props.put(&quot;batch.size&quot;, 16384);//批次大小
        props.put(&quot;linger.ms&quot;, 1);//等待时间
        props.put(&quot;buffer.memory&quot;, 33554432);//RecordAccumulator缓冲区大小
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
        for (int i = 0; i &lt; 100; i++) &#123;
            producer.send(new ProducerRecord&lt;String, String&gt;(&quot;first&quot;, Integer.toString(i), Integer.toString(i)), new Callback() &#123;

                //回调函数，该方法会在Producer收到ack时调用，为异步调用
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) &#123;
                    if (exception == null) &#123;
                        System.out.println(&quot;success-&gt;&quot; + metadata.offset());
                    &#125; else &#123;
                        exception.printStackTrace();
                    &#125;
                &#125;
            &#125;);
        &#125;
        producer.close();
    &#125;
&#125;
</code></pre>
<h4 id="三、同步发送API"><a href="#三、同步发送API" class="headerlink" title="三、同步发送API"></a>三、同步发送API</h4><p>同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。</p>
<p>由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方发即可。</p>
<pre><code class="java">package com.atguigu.kafka;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;
import java.util.concurrent.ExecutionException;

public class CustomProducer &#123;

    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);//kafka集群，broker-list
        props.put(&quot;acks&quot;, &quot;all&quot;);
        props.put(&quot;retries&quot;, 1);//重试次数
        props.put(&quot;batch.size&quot;, 16384);//批次大小
        props.put(&quot;linger.ms&quot;, 1);//等待时间
        props.put(&quot;buffer.memory&quot;, 33554432);//RecordAccumulator缓冲区大小
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
        for (int i = 0; i &lt; 100; i++) &#123;
            producer.send(new ProducerRecord&lt;String, String&gt;(&quot;first&quot;, Integer.toString(i), Integer.toString(i))).get();
        &#125;
        producer.close();
    &#125;
&#125;
</code></pre>
<h3 id="Consumer-API"><a href="#Consumer-API" class="headerlink" title="Consumer API"></a>Consumer API</h3><p>Consumer消费数据时的可靠性是很容易保证的，因为数据在Kafka中是持久化的，故不用担心数据丢失问题。</p>
<p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p>
<p>所以offset的维护是Consumer消费数据是必须考虑的问题。</p>
<h4 id="一、手动提交offset"><a href="#一、手动提交offset" class="headerlink" title="一、手动提交offset"></a>一、手动提交offset</h4><p>1）导入依赖</p>
<pre><code class="xml">&lt;dependency&gt;
&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
&lt;version&gt;0.11.0.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>2）编写代码<br>需要用到的类：</p>
<pre><code>KafkaConsumer：需要创建一个消费者对象，用来消费数据
ConsumerConfig：获取所需的一系列配置参数
ConsuemrRecord：每条数据都要封装成一个ConsumerRecord对象
</code></pre>
<pre><code class="java">package com.atguigu.kafka;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.util.Arrays;
import java.util.Properties;

public class CustomConsumer &#123;

    public static void main(String[] args) &#123;
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);
        props.put(&quot;group.id&quot;, &quot;test&quot;);//消费者组，只要group.id相同，就属于同一个消费者组
        props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);//自动提交offset
       
        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(Arrays.asList(&quot;first&quot;));
        while (true) &#123;
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
            for (ConsumerRecord&lt;String, String&gt; record : records) &#123;
                System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());
            &#125;
            consumer.commitSync();
        &#125;
    &#125;
&#125;
</code></pre>
<p>3）代码分析：</p>
<p>手动提交offset的方法有两种：分别是<strong>commitSync（同步提交）</strong>和<strong>commitAsync（异步提交）</strong>。两者的相同点是，都会将本次poll的一批数据最高的偏移量提交；不同点是，commitSync会失败重试，一直到提交成功（如果由于不可恢复原因导致，也会提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。</p>
<p>4）数据重复消费问题</p>
<p><img src="/cdh/kafka/kafka/image-20200910193111686.png" alt="image-20200910193111686"></p>
<h4 id="二、自动提交offset"><a href="#二、自动提交offset" class="headerlink" title="二、自动提交offset"></a>二、自动提交offset</h4><p>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。<br>自动提交offset的相关参数：<br><strong>enable.auto.commit</strong>：是否开启自动提交offset功能<br><strong>auto.commit.interval.ms</strong>：自动提交offset的时间间隔</p>
<p>以下为自动提交offset的代码：</p>
<pre><code class="java">package com.atguigu.kafka;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.util.Arrays;
import java.util.Properties;

public class CustomConsumer &#123;

    public static void main(String[] args) &#123;
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);
        props.put(&quot;group.id&quot;, &quot;test&quot;);
        props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);
        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(Arrays.asList(&quot;first&quot;));
        while (true) &#123;
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
            for (ConsumerRecord&lt;String, String&gt; record : records)
                System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());
        &#125;
    &#125;
&#125;
</code></pre>
<h4 id="三、重新分区问题"><a href="#三、重新分区问题" class="headerlink" title="三、重新分区问题"></a>三、重新分区问题</h4><pre><code class="java">public class CustomOffsetConsumer &#123;

    public static void main(String[] args) &#123;

        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);
        props.put(&quot;group.id&quot;, &quot;test&quot;);//消费者组，只要group.id相同，就属于同一个消费者组
        props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);//自动提交offset
        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(Arrays.asList(&quot;first&quot;), new ConsumerRebalanceListener() &#123;

            //提交当前负责的分区的offset
            @Override
            public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) &#123;


            &#125;

            //定位新分配的分区的offset
            @Override
            public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) &#123;
                for (TopicPartition partition : partitions) &#123;
                    Long offset = getPartitionOffset(partition);
                    consumer.seek(partition,offset);
                &#125;
            &#125;
        &#125;);


        while (true) &#123;
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
            for (ConsumerRecord&lt;String, String&gt; record : records) &#123;

                System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());
                TopicPartition topicPartition = new TopicPartition(record.topic(), record.partition());
                commitOffset(topicPartition,record.offset()+1);
            &#125;
        &#125;
    &#125;

    private static void commitOffset(TopicPartition topicPartition, long l) &#123;

    &#125;

    private static Long getPartitionOffset(TopicPartition partition) &#123;
        return null;
    &#125;

&#125;
</code></pre>
<h3 id="自定义Interceptor"><a href="#自定义Interceptor" class="headerlink" title="自定义Interceptor"></a>自定义Interceptor</h3><h4 id="拦截器原理"><a href="#拦截器原理" class="headerlink" title="拦截器原理"></a>拦截器原理</h4><p>Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。<br>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如<strong>修改消息</strong>等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。</p>
<p>Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：<br><strong>（1）configure(configs)</strong><br>获取配置信息和初始化数据时调用。<br><strong>（2）onSend(ProducerRecord)：</strong><br>该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。<br><strong>（3）onAcknowledgement(RecordMetadata, Exception)：</strong><br><strong>该方法会在消息从RecordAccumulator成功发送到Kafka Broker之后，或者在发送过程中失败时调用</strong>。并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率。<br><strong>（4）close：</strong><br>关闭interceptor，主要用于执行一些资源清理工作<br>如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外<strong>倘若指定了多个interceptor，则producer将按照指定顺序调用它们</strong>，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</p>
<h4 id="拦截器案例"><a href="#拦截器案例" class="headerlink" title="拦截器案例"></a>拦截器案例</h4><p>需求：</p>
<p>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。</p>
<p><img src="/cdh/kafka/kafka/image-20200910225802854.png" alt="image-20200910225802854"></p>
<h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><h5 id="（1）增加时间戳拦截器"><a href="#（1）增加时间戳拦截器" class="headerlink" title="（1）增加时间戳拦截器"></a>（1）增加时间戳拦截器</h5><pre><code class="java">package com.atguigu.kafka.interceptor;
import java.util.Map;
import org.apache.kafka.clients.producer.ProducerInterceptor;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

public class TimeInterceptor implements ProducerInterceptor&lt;String, String&gt; &#123;

    @Override
    public void configure(Map&lt;String, ?&gt; configs) &#123;

    &#125;

    @Override
    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123;
        // 创建一个新的record，把时间戳写入消息体的最前部
        return new ProducerRecord(record.topic(), record.partition(), record.timestamp(), record.key(),
                System.currentTimeMillis() + &quot;,&quot; + record.value().toString());
    &#125;

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123;

    &#125;

    @Override
    public void close() &#123;

    &#125;
&#125;
</code></pre>
<h5 id="（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器"><a href="#（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器" class="headerlink" title="（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器"></a>（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器</h5><pre><code class="java">package com.atguigu.kafka.interceptor;
import java.util.Map;
import org.apache.kafka.clients.producer.ProducerInterceptor;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

public class CounterInterceptor implements ProducerInterceptor&lt;String, String&gt;&#123;
    private int errorCounter = 0;
    private int successCounter = 0;

    @Override
    public void configure(Map&lt;String, ?&gt; configs) &#123;
        
    &#125;

    @Override
    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123;
         return record;
    &#125;

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123;
        // 统计成功和失败的次数
        if (exception == null) &#123;
            successCounter++;
        &#125; else &#123;
            errorCounter++;
        &#125;
    &#125;

    @Override
    public void close() &#123;
        // 保存结果
        System.out.println(&quot;Successful sent: &quot; + successCounter);
        System.out.println(&quot;Failed sent: &quot; + errorCounter);
    &#125;
&#125;
</code></pre>
<h5 id="（3）producer主程序"><a href="#（3）producer主程序" class="headerlink" title="（3）producer主程序"></a>（3）producer主程序</h5><pre><code class="java">package com.atguigu.kafka.interceptor;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;

public class InterceptorProducer &#123;

    public static void main(String[] args) throws Exception &#123;
        // 1 设置配置信息
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);
        props.put(&quot;acks&quot;, &quot;all&quot;);
        props.put(&quot;retries&quot;, 0);
        props.put(&quot;batch.size&quot;, 16384);
        props.put(&quot;linger.ms&quot;, 1);
        props.put(&quot;buffer.memory&quot;, 33554432);
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        
        // 2 构建拦截链
        List&lt;String&gt; interceptors = new ArrayList&lt;&gt;();
        interceptors.add(&quot;com.atguigu.kafka.interceptor.TimeInterceptor&quot;); 	interceptors.add(&quot;com.atguigu.kafka.interceptor.CounterInterceptor&quot;); 
        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);
         
        String topic = &quot;first&quot;;
        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
        
        // 3 发送消息
        for (int i = 0; i &lt; 10; i++) &#123;
            
            ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;message&quot; + i);
            producer.send(record);
        &#125;
         
        // 4 一定要关闭producer，这样才会调用interceptor的close方法
        producer.close();
    &#125;
&#125;
</code></pre>
<h5 id="（4）测试"><a href="#（4）测试" class="headerlink" title="（4）测试"></a>（4）测试</h5><p>（1）在kafka上启动消费者，然后运行客户端java程序。</p>
<pre><code class="java">[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh \
--bootstrap-server hadoop102:9092 --from-beginning --topic first

1501904047034,message0
1501904047225,message1
1501904047230,message2
1501904047234,message3
1501904047236,message4
1501904047240,message5
1501904047243,message6
1501904047246,message7
1501904047249,message8
1501904047252,message9
</code></pre>
<h2 id="Kafka监控组件"><a href="#Kafka监控组件" class="headerlink" title="Kafka监控组件"></a>Kafka监控组件</h2><h3 id="Kafka-Monitor"><a href="#Kafka-Monitor" class="headerlink" title="Kafka Monitor"></a>Kafka Monitor</h3><p>1.上传jar包KafkaOffsetMonitor-assembly-0.4.6.jar到集群</p>
<p>2.在&#x2F;opt&#x2F;module&#x2F;下创建kafka-offset-console文件夹</p>
<p>3.将上传的jar包放入刚创建的目录下</p>
<p>4.在&#x2F;opt&#x2F;module&#x2F;kafka-offset-console目录下创建启动脚本start.sh，内容如下：</p>
<pre><code class="sh">#!/bin/bash
java -cp KafkaOffsetMonitor-assembly-0.4.6-SNAPSHOT.jar \
com.quantifind.kafka.offsetapp.OffsetGetterWeb \
--offsetStorage kafka \
--kafkaBrokers hadoop102:9092,hadoop103:9092,hadoop104:9092 \
--kafkaSecurityProtocol PLAINTEXT \
--zk hadoop102:2181,hadoop103:2181,hadoop104:2181 \
--port 8086 \
--refresh 10.seconds \
--retain 2.days \
--dbName offsetapp_kafka &amp;
</code></pre>
<p>5.在&#x2F;opt&#x2F;module&#x2F;kafka-offset-console目录下创建mobile-logs文件夹</p>
<pre><code class="shell">mkdir /opt/module/kafka-offset-console/mobile-logs
</code></pre>
<p>6.启动KafkaMonitor</p>
<pre><code class="shell">./start.sh
</code></pre>
<p>7.登录页面hadoop102:8086端口查看详情</p>
<h3 id="Kafka-Manager"><a href="#Kafka-Manager" class="headerlink" title="Kafka Manager"></a>Kafka Manager</h3><p>1.上传压缩包kafka-manager-1.3.3.15.zip到集群</p>
<p>2.解压到&#x2F;opt&#x2F;module</p>
<p>3.修改配置文件conf&#x2F;application.conf</p>
<p>kafka-manager.zkhosts&#x3D;”kafka-manager-zookeeper:2181”</p>
<p>修改为：</p>
<p>kafka-manager.zkhosts&#x3D;”hadoop102:2181,hadoop103:2181,hadoop104:2181”</p>
<p>4.启动kafka-manager</p>
<p>bin&#x2F;kafka-manager</p>
<p>5.登录hadoop102:9000页面查看详细信息</p>
<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><h4 id="1-Kafka中的ISR、AR又代表什么？"><a href="#1-Kafka中的ISR、AR又代表什么？" class="headerlink" title="1.Kafka中的ISR、AR又代表什么？"></a>1.Kafka中的ISR、AR又代表什么？</h4><pre><code>ISR：与leader同步的follower集合
AR：分区的全部副本
</code></pre>
<h4 id="2-Kafka中的HW、LEO等分别代表什么？"><a href="#2-Kafka中的HW、LEO等分别代表什么？" class="headerlink" title="2.Kafka中的HW、LEO等分别代表什么？"></a>2.Kafka中的HW、LEO等分别代表什么？</h4><pre><code>HW:分区副本中最小的偏移量
LEO：一个分区中所有副本最小的偏移量
</code></pre>
<h4 id="3-Kafka中是怎么体现消息顺序性的？"><a href="#3-Kafka中是怎么体现消息顺序性的？" class="headerlink" title="3.Kafka中是怎么体现消息顺序性的？"></a>3.Kafka中是怎么体现消息顺序性的？</h4><pre><code>kafka的每个分区数据是有序的，消费者消费数据都有offset，能够保证数据有序性
kafka写入数据可以指定partition，将相同的key发送到同一个partition里，保证业务相同的key有序。
</code></pre>
<h4 id="4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"><a href="#4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？" class="headerlink" title="4.Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"></a>4.Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</h4><h4 id><a href="#" class="headerlink" title></a><img src="/cdh/kafka/kafka/jo6w29tl4b.png" alt="jo6w29tl4b"></h4><pre><code>处理顺序：拦截器-》序列化器-》分区器
</code></pre>
<h4 id="5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"><a href="#5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？" class="headerlink" title="5.Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"></a>5.Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？</h4><pre><code>整体架构：Producer生产者启动main西安城，数据经过拦截器，序列化器，分区器后，通过异步调用RecordAccumulator的sender西安城来实现消息的批次发送到topic
</code></pre>
<h4 id="6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"><a href="#6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？" class="headerlink" title="6.“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"></a>6.“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？</h4><pre><code>正确。
</code></pre>
<h4 id="7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？"><a href="#7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？" class="headerlink" title="7.消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？"></a>7.消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？</h4><pre><code>offset+1
</code></pre>
<h4 id="8-有哪些情形会造成重复消费？"><a href="#8-有哪些情形会造成重复消费？" class="headerlink" title="8.有哪些情形会造成重复消费？"></a>8.有哪些情形会造成重复消费？</h4><pre><code>d
</code></pre>
<h4 id="9-那些情景会造成消息漏消费？"><a href="#9-那些情景会造成消息漏消费？" class="headerlink" title="9.那些情景会造成消息漏消费？"></a>9.那些情景会造成消息漏消费？</h4><pre><code>
</code></pre>
<h4 id="10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"><a href="#10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？" class="headerlink" title="10.当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"></a>10.当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</h4><p>​    1）会在zookeeper中的&#x2F;brokers&#x2F;topics节点下创建一个新的topic节点，如：&#x2F;brokers&#x2F;topics&#x2F;first<br>​    2）触发Controller的监听程序<br>​    3）kafka Controller 负责topic的创建工作，并更新metadata cache<br>11.topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？<br>12.topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？<br>13.Kafka有内部的topic吗？如果有是什么？有什么所用？<br>14.Kafka分区分配的概念？<br>15.简述Kafka的日志目录结构？<br>16.如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？<br>17.聊一聊Kafka Controller的作用？<br>18.Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？<br>19.失效副本是指什么？有那些应对措施？<br>20.Kafka的那些设计让它有如此高的性能？<br>21.扩展问题，怎么保证exactly one语义</p>
<h4 id="11-kafka和其他的消息队列有什么区别？"><a href="#11-kafka和其他的消息队列有什么区别？" class="headerlink" title="11. kafka和其他的消息队列有什么区别？"></a>11. kafka和其他的消息队列有什么区别？</h4><pre><code>kafka是分布式的消息队列，用来缓存解耦削峰异步请求等作用，其他的消息队列如rocketmq，activemq等消息队列都是全局有序的，先进先出。但是kafka虽然有先进先出的特性，但他有topic的概念，分区进行存储，每个分区的数据是有序的，无法保证topic整体的数据有序性
其他的消息队列是严格的先进先出的，是全局有序的。
</code></pre>
<h4 id="12-kafka怎么保证消费者不丢失数据？"><a href="#12-kafka怎么保证消费者不丢失数据？" class="headerlink" title="12. kafka怎么保证消费者不丢失数据？"></a>12. kafka怎么保证消费者不丢失数据？</h4><p>处理完毕数据后在进行offset的提交，虽然有可能会重复消费。</p>
<h4 id="13-Kafka事务"><a href="#13-Kafka事务" class="headerlink" title="13. Kafka事务"></a>13. Kafka事务</h4><p>Kafka 从 0.11 版本开始支持了事务机制。具体来说，Kafka 生产者在同一个事务内提交到多个分区的消息，要么同时成功，要么同时失败。这一保证在生产者运行时出现异常甚至宕机重启之后仍然成立。</p>
<h4 id="14-多条数据如何放入同一个topic的分区中？"><a href="#14-多条数据如何放入同一个topic的分区中？" class="headerlink" title="14.多条数据如何放入同一个topic的分区中？"></a>14.多条数据如何放入同一个topic的分区中？</h4><ol>
<li><p>可以使用自定义分区器。</p>
</li>
<li><p>默认条件下，指定相同的key即可放松到同一个partition中。</p>
</li>
</ol>
<h4 id="15-kafka怎么保证精准一次推送？"><a href="#15-kafka怎么保证精准一次推送？" class="headerlink" title="15.kafka怎么保证精准一次推送？"></a>15.kafka怎么保证精准一次推送？</h4><p>旧版本中（0.11之前）：</p>
<p>生产者端：ack设置成-1</p>
<p>消费者端：取消自动提交offset，在消费完毕后进行提交offset。</p>
<p>新版本中（0.11之后）：</p>
<p>kafka 0.11.0.0版本引入了idempotent  producer机制，在这个机制中同一消息可能被producer发送多次，但是在broker端只会写入一次，他为每一条消息编号去重，而且对kafka开销影响不大。</p>
<p>如何设置开启呢？ 需要设置producer端的新参数  enable.idempotent  为true。</p>
<h4 id="16-kafka怎么保证精准一次消费？"><a href="#16-kafka怎么保证精准一次消费？" class="headerlink" title="16.kafka怎么保证精准一次消费？"></a>16.kafka怎么保证精准一次消费？</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wangsl754/article/details/107479977">https://blog.csdn.net/wangsl754/article/details/107479977</a></p>
<ol>
<li><strong>方案一：利用关系型数据库的事务进行处理</strong></li>
<li><strong>方案二：手动提交偏移量+开启幂等性处理</strong></li>
</ol>
<p>但是如果数据保存了，没等偏移量提交进程挂了，数据会被<strong>重复消费</strong>。怎么办？那就要把数据的保存做成幂等性保存。即同一批数据反复保存多次，数据不会翻倍，保存一次和保存一百次的效果是一样的。如果能做到这个，就达到了幂等性保存，就不用担心数据会重复了。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">三山</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://star-light-star-bright.github.io/cdh/kafka/kafka/">https://star-light-star-bright.github.io/cdh/kafka/kafka/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">三山</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/CDH/">
                                    <span class="chip bg-color">CDH</span>
                                </a>
                            
                                <a href="/tags/Kafka/">
                                    <span class="chip bg-color">Kafka</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/cdh/kafka/kafka2.2.cdh-ming-ling-xing-ming-ling/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/23.jpg" class="responsive-img" alt="Kafka2.2.0命令">
                        
                        <span class="card-title">Kafka2.2.0命令</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-11-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/CDH/" class="post-category">
                                    CDH
                                </a>
                            
                            <a href="/categories/CDH/Kafka/" class="post-category">
                                    Kafka
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/CDH/">
                        <span class="chip bg-color">CDH</span>
                    </a>
                    
                    <a href="/tags/Kafka/">
                        <span class="chip bg-color">Kafka</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/hexo-da-jian-ge-ren-bo-ke/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="Hexo搭建个人博客">
                        
                        <span class="card-title">Hexo搭建个人博客</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-11-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/hexo%E6%90%AD%E5%BB%BA/" class="post-category">
                                    hexo搭建
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/hexo%E6%90%AD%E5%BB%BA/">
                        <span class="chip bg-color">hexo搭建</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2025</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">三山</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/blinkfox" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1181062873@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2234607886" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2234607886" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
